
<div><font color="#444444">
<h2 class="margined">Holographic Telepresence in Augmented Reality using Microsoft Kinect</h2>
<p align="justify" class="margined">This project was led by me and was sponsored by the Diode SIG, IEEE-NITK (2012-2013). In this project Kinect's RGB and Depth information of what it "sees" is processed to track and extract the point cloud of a human and reconstruct it as a mesh/3D model which is then rendered on an AR marker. The pointcloud library (PCL) was used to capture pointcloud data from Kinect and Augmented Reality Toolkit (ARtoolkit) for the AR graphic rendering on the marker. This project was abandoned when I graduated out of NITK. If you are interested in this project, feel free to use the code or to contact me for any information regarding this. The code for this project can be found <a style="all:unset; color:#0000FF;" onmouseover="this.style.textDecoration='underline'; this.style.color='red';" onmouseout="this.style.textDecoration='none'; this.style.color='blue';" href="https://github.com/nishanthprakash/HTAR.git" target="_blank">here.</a><br/><br/><i>Some screenshots:</i><br>This screenshot shows realtime capture of pointcloud data from Kinect.<br/><br/>
<img src="./nishanthprakash_files/tr1.jpg" width="495" height="330" style="margin:auto;display:block;"><br/><br/>This screen shot shows approximate segmentation of the human based on position of focus of the camera.<br><br> 
<img src="./nishanthprakash_files/tr2.jpg" width="495" height="330" style="margin:auto;display:block;"><br/><br/>This one is a demonstration of Augmented Reality using a cube graphic; for holographic telepresence communication, the cube would be replaced by the pointcloud or a triangulated rendering of the pointcloud of the human speaker.<br/><br/>
<img src="./nishanthprakash_files/tr3.png" width="495" height="330" style="margin:auto;display:block;">
</p>
</font>
</div>


